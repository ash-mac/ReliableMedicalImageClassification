@article{Selvaraju_2019,
	doi = {10.1007/s11263-019-01228-7},
  
	url = {https://doi.org/10.1007\%2Fs11263-019-01228-7},
  
	year = 2019,
	month = {oct},
  
	publisher = {Springer Science and Business Media {LLC}
},	volume = {128},
  
	number = {2},
  
	pages = {336--359},
  
	author = {Ramprasaath R. Selvaraju and Michael Cogswell and Abhishek Das and Ramakrishna Vedantam and Devi Parikh and Dhruv Batra},
  
	title = {Grad-{CAM}: Visual Explanations from Deep Networks via Gradient-Based Localization},
  
	journal = {International Journal of Computer Vision}
}

@misc{ribeiro2016why,
      title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1602.04938},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{MAHAPATRA2022102551,
title = {Interpretability-Guided Inductive Bias For Deep Learning Based Medical Image},
journal = {Medical Image Analysis},
volume = {81},
pages = {102551},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102551},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522001980},
author = {Dwarikanath Mahapatra and Alexander Poellinger and Mauricio Reyes},
keywords = {Interpretability, Inductive bias, Medical image classification, Medical image segmentation},
abstract = {Deep learning methods provide state of the art performance for supervised learning based medical image analysis. However it is essential that trained models extract clinically relevant features for downstream tasks as, otherwise, shortcut learning and generalization issues can occur. Furthermore in the medical field, trustability and transparency of current deep learning systems is a much desired property. In this paper we propose an interpretability-guided inductive bias approach enforcing that learned features yield more distinctive and spatially consistent saliency maps for different class labels of trained models, leading to improved model performance. We achieve our objectives by incorporating a class-distinctiveness loss and a spatial-consistency regularization loss term. Experimental results for medical image classification and segmentation tasks show our proposed approach outperforms conventional methods, while yielding saliency maps in higher agreement with clinical experts. Additionally, we show how information from unlabeled images can be used to further boost performance. In summary, the proposed approach is modular, applicable to existing network architectures used for medical imaging applications, and yields improved learning rates, model robustness, and model interpretability.}
}

@article{liu2019comparison,
  title={A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis},
  author={Liu, Xiaoxuan and Faes, Livia and Kale, Aditya U and Wagner, Siegfried K and Fu, Dun Jack and Bruynseels, Alice and Mahendiran, Thushika and Moraes, Gabriella and Shamdas, Mohith and Kern, Christoph and others},
  journal={The lancet digital health},
  volume={1},
  number={6},
  pages={e271--e297},
  year={2019},
  publisher={Elsevier}
}

@article{perez2017effectiveness,
  title={The effectiveness of data augmentation in image classification using deep learning},
  author={Perez, Luis and Wang, Jason},
  journal={arXiv preprint arXiv:1712.04621},
  year={2017}
}

@article{hino2020active,
  title={Active learning: Problem settings and recent developments},
  author={Hino, Hideitsu},
  journal={arXiv preprint arXiv:2012.04225},
  year={2020}
}

@inproceedings{tan2018survey,
  title={A survey on deep transfer learning},
  author={Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
  booktitle={Artificial Neural Networks and Machine Learning--ICANN 2018: 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part III 27},
  pages={270--279},
  year={2018},
  organization={Springer}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{montavon2017explaining,
  title={Explaining nonlinear classification decisions with deep taylor decomposition},
  author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Pattern recognition},
  volume={65},
  pages={211--222},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{binder2016layer,
  title={Layer-wise relevance propagation for neural networks with local renormalization layers},
  author={Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  booktitle={Artificial Neural Networks and Machine Learning--ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II 25},
  pages={63--71},
  year={2016},
  organization={Springer}
}

@article{goyal2022inductive,
  title={Inductive biases for deep learning of higher-level cognition},
  author={Goyal, Anirudh and Bengio, Yoshua},
  journal={Proceedings of the Royal Society A},
  volume={478},
  number={2266},
  pages={20210068},
  year={2022},
  publisher={The Royal Society}
}

@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{degrave2021ai,
  title={AI for radiographic COVID-19 detection selects shortcuts over signal},
  author={DeGrave, Alex J and Janizek, Joseph D and Lee, Su-In},
  journal={Nature Machine Intelligence},
  volume={3},
  number={7},
  pages={610--619},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={Pmlr}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}

@inproceedings{yuan2021large,
  title={Large-scale robust deep auc maximization: A new surrogate loss and empirical studies on medical image classification},
  author={Yuan, Zhuoning and Yan, Yan and Sonka, Milan and Yang, Tianbao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3040--3049},
  year={2021}
}

@inproceedings{lotfy2019investigation,
  title={Investigation of focal loss in deep learning models for femur fractures classification},
  author={Lotfy, Mayar and Shubair, Raed M and Navab, Nassir and Albarqouni, Shadi},
  booktitle={2019 International Conference on Electrical and Computing Technologies and Applications (ICECTA)},
  pages={1--4},
  year={2019},
  organization={IEEE}
}

@article{tran2019improving,
  title={Improving accuracy of lung nodule classification using deep learning with focal loss},
  author={Tran, Giang Son and Nghiem, Thi Phuong and Nguyen, Van Thi and Luong, Chi Mai and Burie, Jean-Christophe},
  journal={Journal of healthcare engineering},
  volume={2019},
  year={2019},
  publisher={Hindawi}
}

@inproceedings{niculescu2005predicting,
  title={Predicting good probabilities with supervised learning},
  author={Niculescu-Mizil, Alexandru and Caruana, Rich},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={625--632},
  year={2005}
}

@article{murphy1977reliability,
  title={Reliability of subjective probability forecasts of precipitation and temperature},
  author={Murphy, Allan H and Winkler, Robert L},
  journal={Journal of the Royal Statistical Society Series C: Applied Statistics},
  volume={26},
  number={1},
  pages={41--47},
  year={1977},
  publisher={Oxford University Press}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International conference on machine learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR}
}

@inproceedings{kumar2018trainable,
  title={Trainable calibration measures for neural networks from kernel mean embeddings},
  author={Kumar, Aviral and Sarawagi, Sunita and Jain, Ujjwal},
  booktitle={International Conference on Machine Learning},
  pages={2805--2814},
  year={2018},
  organization={PMLR}
}

@inproceedings{zhang2018noisy,
  title={Noisy natural gradient as variational inference},
  author={Zhang, Guodong and Sun, Shengyang and Duvenaud, David and Grosse, Roger},
  booktitle={International conference on machine learning},
  pages={5852--5861},
  year={2018},
  organization={PMLR}
}

@article{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{wen2020batchensemble,
  title={Batchensemble: an alternative approach to efficient ensemble and lifelong learning},
  author={Wen, Yeming and Tran, Dustin and Ba, Jimmy},
  journal={arXiv preprint arXiv:2002.06715},
  year={2020}
}

@article{thulasidasan2019mixup,
  title={On mixup training: Improved calibration and predictive uncertainty for deep neural networks},
  author={Thulasidasan, Sunil and Chennupati, Gopinath and Bilmes, Jeff A and Bhattacharya, Tanmoy and Michalak, Sarah},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wen2020combining,
  title={Combining ensembles and data augmentation can harm your calibration},
  author={Wen, Yeming and Jerfel, Ghassen and Muller, Rafael and Dusenberry, Michael W and Snoek, Jasper and Lakshminarayanan, Balaji and Tran, Dustin},
  journal={arXiv preprint arXiv:2010.09875},
  year={2020}
}

@inproceedings{zadrozny2001obtaining,
  title={Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers},
  author={Zadrozny, Bianca and Elkan, Charles},
  booktitle={Icml},
  volume={1},
  pages={609--616},
  year={2001}
}

@inproceedings{zadrozny2002transforming,
  title={Transforming classifier scores into accurate multiclass probability estimates},
  author={Zadrozny, Bianca and Elkan, Charles},
  booktitle={Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={694--699},
  year={2002}
}

@inproceedings{naeini2015obtaining,
  title={Obtaining well calibrated probabilities using bayesian binning},
  author={Naeini, Mahdi Pakdaman and Cooper, Gregory and Hauskrecht, Milos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{platt1999probabilistic,
  title={Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods},
  author={Platt, John and others},
  journal={Advances in large margin classifiers},
  volume={10},
  number={3},
  pages={61--74},
  year={1999},
  publisher={Cambridge, MA}
}
@misc{havasi2021training,
      title={Training independent subnetworks for robust prediction}, 
      author={Marton Havasi and Rodolphe Jenatton and Stanislav Fort and Jeremiah Zhe Liu and Jasper Snoek and Balaji Lakshminarayanan and Andrew M. Dai and Dustin Tran},
      year={2021},
      eprint={2010.06610},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{irvin2019chexpert,
  title={Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison},
  author={Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and Ciurea-Ilcus, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={590--597},
  year={2019}
}