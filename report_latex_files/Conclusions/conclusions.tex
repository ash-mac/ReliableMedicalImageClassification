\def\baselinestretch{1}
\chapter{Conclusion}
\ifpdf
    \graphicspath{{Conclusions/ConclusionsFigs/PNG/}{Conclusions/ConclusionsFigs/PDF/}{Conclusions/ConclusionsFigs/}}
\else
    \graphicspath{{Conclusions/ConclusionsFigs/EPS/}{Conclusions/ConclusionsFigs/}}
\fi

\def\baselinestretch{1.66}

We have investigated the role of interpretability and calibration in medical image classification tasks. We were unable to show any improvement with the help of loss functions which are Class Distinctiveness Loss and Spatial Coherence Loss. We improved the performance of custom loss function by using our proposed modified pipeline. However, the performance of the modified pipeline was still worse than the Weighted Cross Entropy model. We attempted to fix this by changing various hyperparameters like learning rate, dropout rate and $\lambda1$ value. Despite our efforts, we were not able to show any significant improvement. Moreover, we were not able to verify the quality of saliency maps generated by different methods as we don't have expertise in medical domain. We also experimented with different architectures apart from DenseNet121 such as ResNet101 and VGG19. We also explored the possibility of using Multi Input Multi Output (MIMO) Network in our training setup.

We pivoted in a different direction by studying the class imbalance problem. The 5 classes we chose for training and evaluation from the CheXpert didn't have a balanced representation of each class. This imbalance reflected in the model performance too as the AUC of each class varied with each other. We incorporated two new loss functions which are Focal Loss and DeepAUC Loss. We analysed the model performance under 3 different loss functions and found Focal Loss to perform marginally better than Cross Entropy Loss. DeepAUC Loss was not able to match performance of other two loss functions. Meanwhile, we were able to improve the mean AUC of Cross Entropy model from 0.80, which we obtained in our earlier experiments, to 0.88 which we attribute to using better set of hyperparameters. We also wanted to make sure that our trained models are reliable enough for deployment in real life applications which is very important in the context of medical domain. We investigated how calibrated the model probabilities are and further calibrated them using Temperature Scaling. We observed that the Cross Entropy model was the most calibrated, however all 3 models were calibrated to similar degree as the Expected Calibration Errors decreased for all 3 models after applying Temperature Scaling. Most of the medical classification models mainly focus on the accuracy only without focusing on the model calibration. We argue that it is very important to calibrate the models and the same reflected in our experiments as well. We have analysed the effects of using saliency maps to improve accuracy and interpretability, investigated the use of different loss functions to address class imbalance problem and proved the importance of model calibration.

%%% ----------------------------------------------------------------------

% ------------------------------------------------------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
